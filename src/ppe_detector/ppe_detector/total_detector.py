import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
from sensor_msgs.msg import Image
from std_msgs.msg import String, Bool
from cv_bridge import CvBridge
import cv2
import numpy as np
import torch
from ultralytics import YOLO
import time

class TotalDetector(Node):
    def __init__(self):
        super().__init__('total_detector_node')
        
        # ==================== íŒŒë¼ë¯¸í„° ====================
        self.declare_parameter('pose_model', 'yolo11n-pose.pt')
        self.declare_parameter('ppe_model', 'models/yolo26n_model/origin2/weights/best.pt')
        self.declare_parameter('target_width', 640)
        self.declare_parameter('skip_frame', 1)       # í”„ë ˆì„ ìŠ¤í‚µ (2~4 ê¶Œì¥)
        self.declare_parameter('enable_debug', True)
        self.declare_parameter('ppe_conf', 0.5)      # ì‹ ë¢°ë„ ì•½ê°„ ë‚®ì¶¤ (ê²€ì¶œë¥  í™•ë³´)
        self.declare_parameter('use_tensorrt', False)
        
        # ==================== ë””ë°”ì´ìŠ¤ ì„¤ì • ====================
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.use_half = (self.device == 'cuda')
        self.get_logger().info(f"ğŸš€ Device: {self.device} (Half: {self.use_half})")

        # ==================== ëª¨ë¸ ë¡œë“œ ====================
        pose_path = self.get_parameter('pose_model').value
        ppe_path = self.get_parameter('ppe_model').value
        use_trt = self.get_parameter('use_tensorrt').value
        
        if use_trt and not pose_path.endswith('.engine'):
            pose_path = pose_path.replace('.pt', '.engine')
            ppe_path = ppe_path.replace('.pt', '.engine')

        try:
            self.get_logger().info("â³ Loading Models...")
            self.pose_model = YOLO(pose_path)
            self.ppe_model = YOLO(ppe_path)
            
            # Fuse ì—°ì‚° (PyTorch ëª¨ë¸ì˜ ê²½ìš° Conv+BN ë ˆì´ì–´ ë³‘í•©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
            if not use_trt:
                self.get_logger().info("âš¡ Fusing layers for speed...")
                # self.pose_model.fuse() # YOLOv11/v8ì€ ë¡œë“œ ì‹œ ìë™ fuse ë  ìˆ˜ ìˆìœ¼ë‚˜ ëª…ì‹œ ê°€ëŠ¥
                
            # ì›œì—…
            dummy = np.zeros((640, 640, 3), dtype=np.uint8)
            self.pose_model(dummy, device=self.device, half=self.use_half, verbose=False)
            self.ppe_model(dummy, device=self.device, half=self.use_half, verbose=False)
            self.get_logger().info("âœ… Models Loaded & Warmed Up")

        except Exception as e:
            self.get_logger().error(f"âŒ Model Load Error: {e}")
            raise e

        # ==================== ROS í†µì‹  ====================
        # Best Effort í•„ìˆ˜ (ì˜ìƒ ëŠê¹€ ë°©ì§€)
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            history=HistoryPolicy.KEEP_LAST,
            depth=1
        )

        self.sub = self.create_subscription(Image, '/image_raw', self.img_callback, qos_profile)
        
        # Publisher (Queue size ì¤„ì„)
        self.pub_debug = self.create_publisher(Image, '/ppe_debug', 2)
        self.pub_status = self.create_publisher(String, '/what_detected', 5)
        self.pub_safe = self.create_publisher(Bool, '/all_detected', 5)

        self.bridge = CvBridge()
        
        # ìºì‹±ëœ ì„¤ì •ê°’
        self.TARGET_WIDTH = self.get_parameter('target_width').value
        self.SKIP_FRAME = self.get_parameter('skip_frame').value
        self.DEBUG_ENABLED = self.get_parameter('enable_debug').value
        self.PPE_CONF = self.get_parameter('ppe_conf').value
        
        # ë¹„ìœ¨ ìƒìˆ˜
        self.RATIO_HEAD = 0.35
        self.RATIO_BODY = 0.40
        self.RATIO_HAND = 0.20
        self.RATIO_EAR = 0.10

        self.frame_cnt = 0
        self.prev_time = time.time()

    @torch.no_grad() # Gradient ê³„ì‚° ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬/ì†ë„ ìµœì í™”)
    def img_callback(self, msg):
        self.frame_cnt += 1
        
        # [ìµœì í™” 1] Bridge ë³€í™˜ ì „ ìŠ¤í‚µ í™•ì¸ (CPU ë¶€í•˜ ëŒ€í­ ê°ì†Œ)
        if self.frame_cnt % self.SKIP_FRAME != 0:
            return

        curr_time = time.time()
        
        # [ìµœì í™” 2] ì´ë¯¸ì§€ ë³€í™˜ ë° ë¦¬ì‚¬ì´ì§•
        try:
            cv_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            h, w = cv_img.shape[:2]
            
            # ë¦¬ì‚¬ì´ì¦ˆ (í•„ìš”í•œ ê²½ìš°ë§Œ)
            if w != self.TARGET_WIDTH:
                scale = self.TARGET_WIDTH / w
                new_h = int(h * scale)
                cv_img = cv2.resize(cv_img, (self.TARGET_WIDTH, new_h), interpolation=cv2.INTER_LINEAR)
        except Exception as e:
            self.get_logger().warn(f"Img conversion failed: {e}")
            return

        # ==================== 1. Pose ì¶”ë¡  ====================
        # classes=[0]ìœ¼ë¡œ ì‚¬ëŒë§Œ í•„í„°ë§ (ë¶ˆí•„ìš”í•œ ê°ì²´ íƒì§€ ë°©ì§€)
        pose_res = self.pose_model(cv_img, device=self.device, half=self.use_half, 
                                 verbose=False, classes=[0], max_det=1) 
                                 # max_det=1: ê°€ì¥ í° ì‚¬ëŒ 1ëª…ë§Œ ë¹ ë¥´ê²Œ ì¡ê¸°

        if not pose_res or not pose_res[0].boxes:
            if self.DEBUG_ENABLED:
                self.publish_debug(cv_img, "No Person", False, 0)
            return

        # ë°ì´í„° ì¶”ì¶œ (CPU ì´ë™ ìµœì†Œí™”)
        res = pose_res[0]
        # boxesê°€ í…ì„œ ìƒíƒœì¼ ìˆ˜ ìˆìŒ. í•œ ë²ˆë§Œ cpuë¡œ ì´ë™
        boxes_cpu = res.boxes.xyxy.cpu().numpy()
        kpts_cpu = res.keypoints.xy.cpu().numpy()[0]
        confs_cpu = res.keypoints.conf.cpu().numpy()[0]
        
        p_bbox = boxes_cpu[0]
        p_width = max(10.0, p_bbox[2] - p_bbox[0])

        # ==================== 2. ROI ê¸°ë°˜ PPE ì¶”ë¡  ====================
        x1, y1, x2, y2 = map(int, p_bbox)
        
        # ROI í´ë¨í•‘ (ì´ë¯¸ì§€ ë²”ìœ„ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ)
        margin = int((x2 - x1) * 0.15)
        ih, iw = cv_img.shape[:2]
        rx1 = max(0, x1 - margin)
        ry1 = max(0, y1 - margin)
        rx2 = min(iw, x2 + margin)
        ry2 = min(ih, y2 + margin)

        # ROIê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ íŒ¨ìŠ¤
        if (rx2 - rx1) < 10 or (ry2 - ry1) < 10:
            return

        person_roi = cv_img[ry1:ry2, rx1:rx2] # Numpy slicingì€ ë¹ ë¦„ (View)

        # PPE ì¶”ë¡ 
        ppe_res = self.ppe_model(person_roi, device=self.device, half=self.use_half,
                               verbose=False, conf=self.PPE_CONF, iou=0.5)

        # PPE ì¢Œí‘œ ë§¤í•‘ìš© ë”•ì…”ë„ˆë¦¬
        detected_ppes = {"helmet": [], "vest": [], "gloves": [], "earplug": []}
        
        if ppe_res and ppe_res[0].boxes:
            # í…ì„œ ì—°ì‚°ì„ ìµœëŒ€í•œ í™œìš©í•˜ê±°ë‚˜, ë£¨í”„ë¥¼ ìµœì†Œí™”
            ppe_boxes = ppe_res[0].boxes
            clss = ppe_boxes.cls.cpu().numpy()
            xys = ppe_boxes.xyxy.cpu().numpy()
            
            names = self.ppe_model.names
            
            for i, cls_idx in enumerate(clss):
                cls_name = names[int(cls_idx)].lower()
                bx1, by1, bx2, by2 = xys[i]
                
                # Global ì¢Œí‘œ ë³€í™˜
                cx = (bx1 + bx2) / 2 + rx1
                cy = (by1 + by2) / 2 + ry1
                
                # ë¬¸ìì—´ í¬í•¨ ê²€ì‚¬ ìµœì í™”
                if "helmet" in cls_name or "hard" in cls_name:
                    detected_ppes["helmet"].append((cx, cy))
                elif "vest" in cls_name:
                    detected_ppes["vest"].append((cx, cy))
                elif "glove" in cls_name:
                    detected_ppes["gloves"].append((cx, cy))
                elif "ear" in cls_name or "plug" in cls_name:
                    detected_ppes["earplug"].append((cx, cy))

        # ==================== 3. ì¢Œí‘œ ê³„ì‚° ë° ë§¤ì¹­ (Pure Math) ====================
        # (ì´ ë¶€ë¶„ì€ Numpy ì—°ì‚°ì´ë¼ ë§¤ìš° ë¹ ë¥´ë¯€ë¡œ ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë˜ í•¨ìˆ˜ í˜¸ì¶œ overheadë§Œ ì œê±°)
        
        # Keypoints Helper
        def get_pt(idx): return kpts_cpu[idx] if confs_cpu[idx] > 0.5 else None

        pt_nose = get_pt(0)
        pt_eye_l, pt_eye_r = get_pt(1), get_pt(2)
        pt_ear_l, pt_ear_r = get_pt(3), get_pt(4)
        pt_sh_l, pt_sh_r = get_pt(5), get_pt(6)
        pt_hip_l, pt_hip_r = get_pt(11), get_pt(12)
        pt_wr_l, pt_wr_r = get_pt(9), get_pt(10)
        pt_el_l, pt_el_r = get_pt(7), get_pt(8)

        # --- Coordinates Logic (Condensed) ---
        eyes_c = (pt_eye_l + pt_eye_r)/2 if (pt_eye_l is not None and pt_eye_r is not None) else None
        
        # Head
        head_c = None
        if pt_nose is not None and eyes_c is not None:
            head_c = eyes_c + (eyes_c - pt_nose) * 2.5
        elif pt_sh_l is not None and pt_sh_r is not None:
            head_c = (pt_sh_l + pt_sh_r)/2 + [0, -p_width*0.35]
            
        # Body
        body_c = None
        sh_c = (pt_sh_l + pt_sh_r)/2 if (pt_sh_l is not None and pt_sh_r is not None) else None
        if sh_c is not None:
            if pt_hip_l is not None and pt_hip_r is not None:
                body_c = sh_c * 0.7 + ((pt_hip_l + pt_hip_r)/2) * 0.3
            else:
                body_c = sh_c + [0, p_width*0.25]
        
        # Hands
        def get_hand(el, wr, is_l):
            if wr is None: return None
            if el is not None: return wr + (wr - el) * 0.4
            offset = p_width * 0.15 * 1.5
            return wr + [0, -offset] if (sh_c is not None and wr[1] < sh_c[1]) else wr + [0, offset]

        hl_c = get_hand(pt_el_l, pt_wr_l, True)
        hr_c = get_hand(pt_el_r, pt_wr_r, False)

        # --- Matching ---
        status = {}
        
        def check(center, ratio, p_type, label, draw_img):
            if center is None: return False
            half = (p_width * ratio) / 2
            x1, y1 = int(center[0]-half), int(center[1]-half)
            x2, y2 = int(center[0]+half), int(center[1]+half)
            
            matched = False
            for (px, py) in detected_ppes[p_type]:
                if x1 <= px <= x2 and y1 <= py <= y2:
                    matched = True
                    break
            
            # [ìµœì í™” 3] Debug Enabledì¼ ë•Œë§Œ ê·¸ë¦¬ê¸° ì—°ì‚° ìˆ˜í–‰
            if self.DEBUG_ENABLED and draw_img is not None:
                color = (0, 255, 0) if matched else (0, 0, 255)
                cv2.rectangle(draw_img, (x1, y1), (x2, y2), color, 2)
                cv2.putText(draw_img, label, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            return matched

        draw_target = cv_img if self.DEBUG_ENABLED else None
        
        status["helmet"] = check(head_c, self.RATIO_HEAD, "helmet", "H", draw_target)
        status["vest"] = check(body_c, self.RATIO_BODY, "vest", "V", draw_target)
        
        l_ok = check(hl_c, self.RATIO_HAND, "gloves", "L_G", draw_target)
        r_ok = check(hr_c, self.RATIO_HAND, "gloves", "R_G", draw_target)
        status["gloves"] = (l_ok or hl_c is None) and (r_ok or hr_c is None)
        if hl_c is None and hr_c is None: status["gloves"] = False

        el_ok = check(pt_ear_l, self.RATIO_EAR, "earplug", "L_E", draw_target)
        er_ok = check(pt_ear_r, self.RATIO_EAR, "earplug", "R_E", draw_target)
        status["earplug"] = (el_ok or pt_ear_l is None) and (er_ok or pt_ear_r is None)
        if pt_ear_l is None and pt_ear_r is None: status["earplug"] = False

        # ==================== 4. ê²°ê³¼ ì „ì†¡ ====================
        required = ["helmet", "vest", "gloves"]
        all_safe = all(status.get(k, False) for k in required)
        
        self.pub_status.publish(String(data=", ".join([k for k,v in status.items() if v])))
        self.pub_safe.publish(Bool(data=all_safe))

        # FPS ê³„ì‚°
        dt = curr_time - self.prev_time
        fps = 1.0 / dt if dt > 0 else 0
        self.prev_time = curr_time

        if self.DEBUG_ENABLED:
            self.publish_debug(cv_img, f"{'SAFE' if all_safe else 'UNSAFE'} {fps:.1f}fps", all_safe, fps)

    def publish_debug(self, img, text, is_safe, fps):
        # [ìµœì í™” 4] ë””ë²„ê·¸ ì´ë¯¸ì§€ ë°œí–‰ ë¹ˆë„ ì œí•œ (FPSê°€ 30ì´ì–´ë„ ë””ë²„ê·¸ëŠ” 15FPSë§Œ ë“±)
        # í•˜ì§€ë§Œ ì—¬ê¸°ì„  ì›ë³¸ ì‹±í¬ë¥¼ ìœ„í•´ ë§¤ë²ˆ ë³´ë‚´ë˜, ì¸ì½”ë”© ì—ëŸ¬ë§Œ ë°©ì–´
        try:
            color = (0, 255, 0) if is_safe else (0, 0, 255)
            cv2.rectangle(img, (0, 0), (250, 40), (0, 0, 0), -1)
            cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            
            # ROI ê·¸ë¦¬ê¸° (ì˜µì…˜)
            # cv2.rectangle(img, (rx1, ry1), (rx2, ry2), (255,255,0), 1)

            self.pub_debug.publish(self.bridge.cv2_to_imgmsg(img, encoding="bgr8"))
        except Exception:
            pass

def main(args=None):
    rclpy.init(args=args)
    node = TotalDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
