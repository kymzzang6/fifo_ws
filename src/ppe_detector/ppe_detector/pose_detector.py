import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import numpy as np
import torch
from ultralytics import YOLO

# ì»¤ìŠ¤í…€ ë©”ì‹œì§€
from yolo_msgs.msg import PoseDetect

class PoseDetector(Node):
    def __init__(self):
        super().__init__('pose_detector_node')
        
        # 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
        if torch.cuda.is_available():
            self.device = 'cuda'
            self.use_half = True 
            self.get_logger().info(f"ğŸš€ CUDA Detected! Using GPU: {torch.cuda.get_device_name(0)}")
        else:
            self.device = 'cpu'
            self.use_half = False
            self.get_logger().warn("âš ï¸ CUDA not available. Running on CPU (slower).")

        # 2. ëª¨ë¸ ì„¤ì •
        self.declare_parameter('model_path', 'yolo11n-pose.pt')
        model_path = self.get_parameter('model_path').value
        
        self.get_logger().info(f"Loading Pose model: {model_path}...")
        try:
            self.model = YOLO(model_path)
            if self.device == 'cuda':
                self.model.to('cuda')
        except Exception as e:
            self.get_logger().error(f"Failed to load model: {e}")

        # 3. í†µì‹  ì„¤ì • (QoS ìˆ˜ì •ë¨: usb_cam í˜¸í™˜ì„± í™•ë³´)
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.BEST_EFFORT,
            history=HistoryPolicy.KEEP_LAST,
            depth=10
        )

        self.subscription = self.create_subscription(
            Image, 
            '/image_raw', 
            self.listener_callback, 
            qos_profile)
        
        self.publisher_ = self.create_publisher(PoseDetect, '/body_points', 10)
        
        self.bridge = CvBridge()

        # [ì„¤ì •] ë¶€ìœ„ë³„ BBox ë¹„ìœ¨ ì„¤ì •
        self.RATIO_HEAD = 0.35  # í—¬ë©§ ê³ ë ¤í•˜ì—¬ ë„‰ë„‰í•˜ê²Œ
        self.RATIO_BODY = 0.40
        self.RATIO_HAND = 0.20
        self.RATIO_EAR = 0.10

    def listener_callback(self, msg):
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        except Exception as e:
            # self.get_logger().error(f"CvBridge Error: {e}")
            return

        # --- ì¶”ë¡  ì‹¤í–‰ ---
        results = self.model(cv_image, device=self.device, half=self.use_half, verbose=False)
        
        body_msg = PoseDetect()
        body_msg.header = msg.header 
        body_msg.header.frame_id = "camera_link"

        # ì´ˆê¸°ê°’ ì„¸íŒ… (-1.0)
        empty_box = [-1.0, -1.0, -1.0, -1.0]
        body_msg.head = empty_box
        body_msg.body = empty_box
        body_msg.hand_left = empty_box
        body_msg.hand_right = empty_box
        body_msg.ear_left = empty_box
        body_msg.ear_right = empty_box

        if len(results) > 0 and results[0].boxes.shape[0] > 0 and results[0].keypoints.xy.shape[1] > 0:
            
            # 1. ì‚¬ëŒ ì „ì²´ ì •ë³´
            person_box = results[0].boxes.xyxy.cpu().numpy()[0]
            p_width = person_box[2] - person_box[0]
            if p_width < 10: p_width = 10.0

            # 2. í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
            keypoints = results[0].keypoints.xy.cpu().numpy()[0]
            confs = results[0].keypoints.conf.cpu().numpy()[0]
            CONF_THRES = 0.5

            def get_pt(idx):
                if confs[idx] > CONF_THRES:
                    return keypoints[idx]
                return None
            
            def create_dynamic_bbox(center_pt, ratio):
                if center_pt is None: return empty_box
                cx, cy = center_pt
                box_size = p_width * ratio
                half_size = box_size / 2
                return [float(cx - half_size), float(cy - half_size), 
                        float(cx + half_size), float(cy + half_size)]

            # Keypoints: 0:Nose, 1:L-Eye, 2:R-Eye, 3:L-Ear, 4:R-Ear, 5:L-Sh, 6:R-Sh, 7:L-El, 8:R-El, 9:L-Wr, 10:R-Wr, 11:L-Hip, 12:R-Hip

            pt_nose = get_pt(0)
            pt_eye_l, pt_eye_r = get_pt(1), get_pt(2)
            pt_ear_l, pt_ear_r = get_pt(3), get_pt(4)
            pt_sh_l, pt_sh_r = get_pt(5), get_pt(6)
            pt_hip_l, pt_hip_r = get_pt(11), get_pt(12)

            # -------------------------------------------------------------------------
            # [1] ë¨¸ë¦¬ (Cranium) ì¢Œí‘œ ê³„ì‚° - 3ë‹¨ê³„ ê³„ì¸µ êµ¬ì¡°
            # -------------------------------------------------------------------------
            head_target = None
            
            # ëˆˆ ì¤‘ì  ê³„ì‚°
            eyes_center = None
            if pt_eye_l is not None and pt_eye_r is not None:
                eyes_center = (pt_eye_l + pt_eye_r) / 2
            elif pt_eye_l is not None: eyes_center = pt_eye_l
            elif pt_eye_r is not None: eyes_center = pt_eye_r

            # [ì „ëµ 1] ì–¼êµ´ ì •ë©´/ì¸¡ë©´: ì½”->ëˆˆ ë²¡í„° ì—°ì¥
            if pt_nose is not None and eyes_center is not None:
                vec_nose_to_eye = eyes_center - pt_nose
                # ë²¡í„°ê°€ ìœ íš¨í•˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ ìˆ˜ì§ ìœ„ë¡œ
                if np.linalg.norm(vec_nose_to_eye) > 1.0:
                    head_target = eyes_center + (vec_nose_to_eye * 2.5) # ì½”-ëˆˆ ê±°ë¦¬ì˜ 2.5ë°° ìœ„
                else:
                    head_target = eyes_center + np.array([0, -p_width * 0.2])

            # [ì „ëµ 2] ë’¤í†µìˆ˜/ì¸¡ë©´: ê·€ ì¤‘ì‹¬ì—ì„œ ìƒìŠ¹
            elif pt_ear_l is not None or pt_ear_r is not None:
                ears = [p for p in [pt_ear_l, pt_ear_r] if p is not None]
                ear_center = np.mean(ears, axis=0)
                if pt_sh_l is not None and pt_sh_r is not None:
                    sh_center = (pt_sh_l + pt_sh_r) / 2
                    vec_neck = ear_center - sh_center
                    head_target = ear_center + (vec_neck * 0.8) # ëª© ê¸¸ì´ë§Œí¼ ë” ìƒìŠ¹
                else:
                    head_target = ear_center + np.array([0, -p_width * 0.25])

            # [ì „ëµ 3] ì™„ì „ ë’·ëª¨ìŠµ: ì²™ì¶” ë²¡í„° ì—°ì¥ (ìƒì²´ ì—­í•™ì  ì¶”ë¡ )
            elif pt_sh_l is not None and pt_sh_r is not None:
                sh_center = (pt_sh_l + pt_sh_r) / 2
                if pt_hip_l is not None and pt_hip_r is not None:
                    hip_center = (pt_hip_l + pt_hip_r) / 2
                    vec_spine = sh_center - hip_center
                    head_target = sh_center + (vec_spine * 0.4) # ì²™ì¶” ê¸¸ì´ì˜ 40% ìœ„
                else:
                    head_target = sh_center + np.array([0, -p_width * 0.35])

            if head_target is not None:
                body_msg.head = create_dynamic_bbox(head_target, self.RATIO_HEAD)

            # -------------------------------------------------------------------------
            # [2] ê¸°íƒ€ ë¶€ìœ„ (ê·€, ëª¸í†µ)
            # -------------------------------------------------------------------------
            if pt_ear_l is not None: body_msg.ear_left = create_dynamic_bbox(pt_ear_l, self.RATIO_EAR)
            if pt_ear_r is not None: body_msg.ear_right = create_dynamic_bbox(pt_ear_r, self.RATIO_EAR)

            sh_center_for_body = None
            if pt_sh_l is not None and pt_sh_r is not None:
                sh_center_for_body = (pt_sh_l + pt_sh_r) / 2
                if pt_hip_l is not None and pt_hip_r is not None:
                    hip_center = (pt_hip_l + pt_hip_r) / 2
                    body_center = sh_center_for_body * 0.7 + hip_center * 0.3
                else:
                    body_center = sh_center_for_body + np.array([0, p_width * 0.25])
                body_msg.body = create_dynamic_bbox(body_center, self.RATIO_BODY)

            # -------------------------------------------------------------------------
            # [3] ì† (Hand) - íŒ”ê¿ˆì¹˜ ë¯¸ê²€ì¶œ ì‹œ ì•ˆë©´ ë¹„ë¡€ ë³´ì • ì ìš©
            # -------------------------------------------------------------------------
            
            # 3-1. ê¸°ì¤€ ê¸¸ì´(Scale) ì‚°ì¶œ: "ì½”-ëˆˆ ê±°ë¦¬"
            unit_length = 0.0
            if pt_nose is not None and eyes_center is not None:
                unit_length = np.linalg.norm(pt_nose - eyes_center)
            
            # ì–¼êµ´ì´ ì•ˆ ë³´ì´ë©´ ì‚¬ëŒ ë„ˆë¹„ë¡œ ëŒ€ì²´ (fallback)
            if unit_length < 5.0: 
                unit_length = p_width * 0.15

            def calc_hand(pt_el, pt_wr):
                if pt_wr is None: return empty_box
                
                target = pt_wr # ê¸°ë³¸ê°’

                if pt_el is not None:
                    # Case A: íŒ”ê¿ˆì¹˜ê°€ ë³´ì„ -> ë²¡í„° ì—°ì¥
                    vec = pt_wr - pt_el
                    target = pt_wr + (vec * 0.4)
                else:
                    # Case B: íŒ”ê¿ˆì¹˜ ì•ˆ ë³´ì„ -> ì•ˆë©´ ë¹„ë¡€ ë³´ì • (ìš”ì²­ì‚¬í•­ ë°˜ì˜)
                    # ì†ê°€ë½ ê¸¸ì´ ì¶”ì • (ëˆˆ-ì½” ê±°ë¦¬ì˜ ì•½ 1.5ë°°)
                    offset_dist = unit_length * 1.5
                    
                    # ì–´ê¹¨ë³´ë‹¤ ì†ì´ ìœ„ì— ìˆìœ¼ë©´ ìœ„ë¡œ, ì•„ë˜ì— ìˆìœ¼ë©´ ì•„ë˜ë¡œ ë³´ì •
                    # (sh_center_for_body ë³€ìˆ˜ í™œìš©)
                    is_hand_up = False
                    if sh_center_for_body is not None:
                        # yê°’ì´ ì‘ì„ìˆ˜ë¡ ìœ„ìª½ì„
                        if pt_wr[1] < sh_center_for_body[1]:
                            is_hand_up = True
                    
                    if is_hand_up:
                        target = pt_wr + np.array([0, -offset_dist]) # ìœ„ë¡œ
                    else:
                        target = pt_wr + np.array([0, offset_dist])  # ì•„ë˜ë¡œ

                return create_dynamic_bbox(target, self.RATIO_HAND)

            body_msg.hand_left = calc_hand(get_pt(7), get_pt(9))
            body_msg.hand_right = calc_hand(get_pt(8), get_pt(10))

        # ë©”ì‹œì§€ ë°œí–‰
        self.publisher_.publish(body_msg)

def main(args=None):
    rclpy.init(args=args)
    node = PoseDetector()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
